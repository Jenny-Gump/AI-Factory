# Pipeline Flow Description (Updated)

This document provides a detailed, step-by-step breakdown of the complete 12-stage content generation pipeline for WordPress article generation.

---

## ИНСТРУКЦИЯ ПО ДИАГНОСТИКЕ ПРОБЛЕМ В ПАЙПЛАЙНЕ

### Как правильно находить проблемы:

#### 1. **ВСЕГДА НАЧИНАТЬ С СЫРЫХ LLM ДАННЫХ**
- **ПЕРВЫМ ДЕЛОМ** проверяй файлы `output/{topic}/*/llm_responses_raw/*.txt`
- Смотри что **ТОЧНО** ушло в LLM и что **ТОЧНО** пришло
- **НЕ полагайся** на логи или промежуточные JSON файлы

#### 2. **СТРОГО СЛЕДОВАТЬ ЦЕПОЧКЕ ДАННЫХ**
- Проверяй **ЧТО** входит в каждый этап (input)
- Проверяй **ЧТО** выходит из каждого этапа (output)
- Найди **ТОЧНОЕ** место где данные меняются неожиданно

#### 3. **НЕ ПРЕДПОЛАГАТЬ - ПРОВЕРЯТЬ ФАКТЫ**
- **НЕ говори** "откуда-то", "возможно", "может быть"
- Читай **РЕАЛЬНЫЕ** файлы с данными
- Смотри **ФАКТИЧЕСКИЕ** запросы/ответы LLM

#### 4. **МЕТОД "ОТ КОНЦА К НАЧАЛУ"**
- Возьми финальный неправильный результат
- Иди **НАЗАД** по этапам до источника проблемы
- Найди где **ИМЕННО** происходит нежелательное изменение

#### 5. **ВСЕГДА ПРОВЕРЯТЬ ПРОМПТЫ**
- Читай промпты которые идут в LLM
- Проверяй есть ли инструкции которые могут вызвать проблему
- Смотри что LLM может неправильно понять

#### 6. **ПОРЯДОК ДИАГНОСТИКИ:**
1. Проверить финальный результат и определить что не так
2. Найти все `llm_responses_raw/*.txt` файлы в папках этапов
3. Проверить каждый ответ LLM в обратном порядке этапов
4. Найти где впервые появляется проблема
5. Проверить промпт этого этапа
6. Исправить промпт или код

**НЕ ТРАТИТЬ ВРЕМЯ НА АНАЛИЗ ЛОГИКИ КОДА БЕЗ ПРОВЕРКИ СЫРЫХ ДАННЫХ!**

---


### Этап 1: Запрос (The Request)

**ВХОДНЫЕ ДАННЫЕ:** 
- Командная строка: `python main.py "тема"`
- Аргумент topic (строка)

**ЦЕЛЬ:** Получить исходную тему для всего пайплайна

**ФУНКЦИИ:**
- `main.py` → `argparse` парсинг аргументов
- Валидация входной строки (не пустая)
- Создание базовой структуры папок `output/{тема}/`

**ПРОЦЕСС:** 
1. Пользователь вводит тему: `"Best prompts for data analysis in 2025"`
2. Система создает slug из темы для имен папок
3. Инициализируется структура директорий для артефактов

**ВЫХОДНЫЕ ДАННЫЕ:**
- `topic: str` - исходная тема
- `topic_slug: str` - нормализованное имя для папок
- Созданы папки: `output/{topic_slug}/01_search/...`

---

### Этап 2: Поиск (Search)

**ВХОДНЫЕ ДАННЫЕ:**
- `topic: str` - тема для поиска
- `FIRECRAWL_API_KEY` - API ключ из .env
- `search_limit: int = 20` - количество результатов

**ЦЕЛЬ:** Найти максимально широкий, но релевантный список URL-адресов по теме

**ФУНКЦИИ:**
- `src/firecrawl_client.py` → `search(topic)`
- Firecrawl Search API (`/v2/search`) запрос
- Обработка ошибок API и таймаутов

**ПРОЦЕСС:**
1. Формируется поисковый запрос без кавычек для широкого охвата
2. POST запрос к `https://api.firecrawl.dev/v2/search`
3. API возвращает топ-20 результатов из поисковой выдачи Google
4. Первичная валидация URL (исключение битых ссылок)

**ВЫХОДНЫЕ ДАННЫЕ:**
```json
[
  {
    "url": "https://example.com/article1",
    "title": "Best Data Analysis Prompts 2025",
    "description": "Complete guide to...",
    "favicon": "https://example.com/favicon.ico"
  }
]
```
**Артефакт:** `output/{тема}/01_search/01_search_results.json`

---

### Этап 3: Парсинг (Parsing)

**ВХОДНЫЕ ДАННЫЕ:**
- Список URL из этапа 2 (20 ссылок)
- `filters/blocked_domains.json` - черный список доменов
- `MIN_CONTENT_LENGTH = 10000` - минимальная длина статьи

**ЦЕЛЬ:** Извлечь основной контент с каждого URL и отсеять неподходящие статьи

**ФУНКЦИИ:**
- `src/processing.py` → `filter_urls()` - фильтрация по черному списку
- `src/firecrawl_client.py` → `scrape_urls()` - конкурентный парсинг
- Firecrawl Scrape API (`/v2/scrape`) с `onlyMainContent: true`
- Валидация длины контента

**ПРОЦЕСС:**
1. **Предварительная фильтрация:** Проверка каждого URL по `blocked_domains.json`
2. **Конкурентное извлечение:** Параллельные запросы к Firecrawl Scrape API
3. **Валидация контента:** Проверка минимальной длины (10000+ символов)
4. **Очистка данных:** Удаление статей с пустым или коротким контентом

**ВЫХОДНЫЕ ДАННЫЕ:**
```json
[
  {
    "url": "https://example.com/article1",
    "title": "Complete Guide to Data Analysis",
    "content": "# Introduction\n\nData analysis has become..." // Markdown
  }
]
```
**Артефакты:**
- `01_clean_urls.json` - URL после фильтрации
- `02_scraped_data.json` - сырые данные от Firecrawl  
- `03_valid_sources.json` - валидированные источники

---

### Этап 4: Оценка (Scoring)

**ВХОДНЫЕ ДАННЫЕ:**
- Валидные источники из этапа 3
- `filters/trusted_sources.json` - белый список доменов
- `topic` - ключевые слова для релевантности
- Веса из `src/config.py`: TRUST_WEIGHT, RELEVANCE_WEIGHT, DEPTH_WEIGHT

**ЦЕЛЬ:** Присвоить каждому источнику объективную трехмерную оценку качества

**ФУНКЦИИ:**
- `src/processing.py` → `calculate_trust_score()` - проверка доверенных доменов
- `src/processing.py` → `calculate_relevance_score()` - анализ ключевых слов
- `src/processing.py` → `calculate_depth_score()` - оценка глубины контента
- Токенизация и анализ текста

**ПРОЦЕСС:**
1. **Трастовость:** Проверка домена по `trusted_sources.json` → (1.0-2.5)
2. **Релевантность:** Подсчет вхождений ключевых слов:
   - В заголовке: вес × 3
   - В тексте: стандартный вес
3. **Глубина:** Длина статьи в символах → нормализация к (0-1)
4. **Агрегация:** Сохранение всех метрик для следующего этапа

**ВЫХОДНЫЕ ДАННЫЕ:**
```json
[
  {
    "url": "https://example.com/article1",
    "title": "Complete Guide",
    "content": "...",
    "trust_score": 2.0,      // 1.0-2.5
    "relevance_score": 0.8,  // 0.0-1.0
    "depth_score": 0.9       // 0.0-1.0
  }
]
```
**Артефакт:** `output/{тема}/03_scoring/scored_sources.json`

---

### Этап 5: Отбор (Selection)

**ВХОДНЫЕ ДАННЫЕ:**
- Оцененные источники с метриками (trust, relevance, depth)
- Веса из config: `TRUST_WEIGHT=0.5`, `RELEVANCE_WEIGHT=0.3`, `DEPTH_WEIGHT=0.2`
- `TOP_SOURCES_COUNT = 5` - количество финалистов

**ЦЕЛЬ:** Выбрать 5 "чемпионов" - лучших источников для LLM анализа

**ФУНКЦИИ:**
- `src/processing.py` → `normalize_scores()` - приведение к единой шкале
- `src/processing.py` → `calculate_final_score()` - взвешенная формула
- `src/processing.py` → `select_top_sources()` - отбор финалистов
- Сортировка по финальному баллу

**ПРОЦЕСС:**
1. **Нормализация:** Все оценки приводятся к шкале (0-1)
2. **Взвешенная формула:** 
   ```python
   Final_Score = (trust * 0.5) + (relevance * 0.3) + (depth * 0.2)
   ```
3. **Сортировка:** Весь список по `Final_Score` (убывание)
4. **Отбор топ-5:** Берутся лучшие источники для LLM этапов

**ВЫХОДНЫЕ ДАННЫЕ:**
```json
[
  {
    "url": "https://example.com/article1",
    "title": "Best Guide",
    "content": "...",
    "trust_score": 2.0,
    "relevance_score": 0.9,
    "depth_score": 0.8,
    "final_score": 1.57,    // Взвешенная сумма
    "rank": 1               // Позиция в рейтинге
  }
]
```
**Артефакт:** `output/{тема}/04_selection/top_5_sources.json`

---

### Этап 6: Очистка (Cleaning)

**ВХОДНЫЕ ДАННЫЕ:**
- Топ-5 источников с "грязным" Markdown контентом
- Паттерны очистки в `src/processing.py`
- Список нежелательных элементов (навигация, реклама)

**ЦЕЛЬ:** Удалить семантический "мусор" и подготовить чистый текст для LLM

**ФУНКЦИИ:**
- `src/processing.py` → `clean_content()` - основная очистка
- `remove_navigation_elements()` - удаление навигации
- `clean_markdown_artifacts()` - очистка разметки
- `normalize_whitespace()` - нормализация пробелов
- Регулярные выражения для паттернов мусора

**ПРОЦЕСС:**
1. **Удаление навигации:** Меню, breadcrumbs, "Related articles"
2. **Очистка рекламы:** Banner текст, партнерские ссылки
3. **Markdown артефакты:** Битая разметка, лишние символы
4. **Нормализация:** Множественные переносы → одинарные
5. **Валидация:** Проверка что основной контент сохранен

**ВЫХОДНЫЕ ДАННЫЕ:**
```json
[
  {
    "url": "https://example.com/article1",
    "title": "Best Guide",
    "cleaned_content": "# Data Analysis Prompts\n\nHere are the most effective..." // Чистый Markdown
  }
]
```
**Артефакт:**
- `final_cleaned_sources.json` - JSON со всеми очищенными источниками

---

### Этап 7: Извлечение структур (Structure Extraction)

**ВХОДНЫЕ ДАННЫЕ:**
- Топ-5 очищенных источников из этапа 6 (`final_cleaned_sources.json`)
- `content_type="basic_articles"`
- Промпт `prompts/basic_articles/01_extract.txt`
- Папка вывода: `06_structure_extraction/`

**ЦЕЛЬ:** Извлечь структурные схемы из каждого источника - разделы, их назначение, фокус контента

**ФУНКЦИИ:**
- `extract_sections_from_article()` с параметром `content_type="basic_articles"`
- LLM анализ через `basic_articles/01_extract.txt` промпт
- Создание JSON схем для каждого источника

**ПРОЦЕСС:**
1. **Итерация по источникам:** Каждый из 5 источников (`source_1`, `source_2`, etc.)
2. **LLM структурный анализ:** Анализ организации контента, H2/H3 заголовков
3. **Извлечение схемы:** JSON с полями `section_title`, `section_description`, `content_focus`, `key_points`, `subsections`
4. **Агрегация:** Все структуры собираются в общий массив `all_structures`
5. **Логирование:** Статистика по каждому источнику (`structures_extracted`)

**ВЫХОДНЫЕ ДАННЫЕ:**
```json
[
  {
    "section_title": "Основы технологии",
    "section_description": "Объяснение базовых принципов и концепций",
    "content_focus": "Образовательный контент для новичков",
    "key_points": "Определения, принципы работы, основные преимущества",
    "subsections": ["Что такое технология", "Принципы работы"]
  }
]
```

**Артефакт:** `06_structure_extraction/all_structures.json`!!!

---

### Этап 8: Создание ультимативной структуры (Ultimate Structure Creation) 🏗️

**ВХОДНЫЕ ДАННЫЕ:**
- `all_structures.json` из этапа 7 (структуры от 5 источников)
- Промпт `prompts/basic_articles/02_create_ultimate_structure.txt`
- `topic` из командной строки для тематической фокусировки
- FREE DeepSeek Chat v3.1 API credentials (via OpenRouter)

**🎯 ЦЕЛЬ:** Объединить 5 структур в единую схему статьи с FAQ и разделом Источники

**ФУНКЦИИ:**
- LLM анализ через функцию создания структуры в `src/llm_processing.py`
- FREE DeepSeek с fallback на Gemini 2.5 при таймаутах
- Синтез структур с добавлением FAQ раздела
- Подготовка схемы для посекционной генерации

**ПРОЦЕСС:**
1. **Анализ структур:** LLM получает все 5 извлеченных структур
2. **Синтез:** Создание единой, наиболее полной структуры статьи
3. **Добавление FAQ:** Автоматическое планирование раздела с частыми вопросами
4. **Добавление Источников:** Планирование раздела с нумерованными ссылками [1]-[5]
5. **Оптимизация:** Логическая последовательность разделов для читаемости

**ВЫХОДНЫЕ ДАННЫЕ:**
```json
[{
  "article_structure": [
    {
      "section_title": "Введение",
      "section_description": "Обзор темы и её важности",
      "subsections": ["Определение", "Актуальность"]
    },
    {
      "section_title": "Основные концепции",
      "section_description": "Ключевые понятия и принципы",
      "subsections": ["Базовые принципы", "Методология"]
    },
    {
      "section_title": "FAQ",
      "section_description": "Часто задаваемые вопросы с развернутыми ответами",
      "subsections": ["Вопрос 1", "Вопрос 2", "Вопрос 3"]
    },
    {
      "section_title": "Полезные ссылки",
      "section_description": "Нумерованные источники для углубленного изучения",
      "subsections": ["Источник 1", "Источник 2", "Источник 3"]
    }
  ]
}]
```

**Артефакты:**
- `ultimate_structure.json` - единая структура статьи для генерации
- `llm_requests/create_structure_request.json` - запрос к LLM
- `llm_responses_raw/create_structure_response.txt` - сырой ответ LLM

**КЛЮЧЕВЫЕ ОСОБЕННОСТИ:**
- **Синтез лучшего:** Объединяет сильные стороны всех 5 источников
- **FAQ интеграция:** Автоматическое планирование интерактивных вопросов
- **Источники:** Подготовка для нумерованных ссылок на источники
- **Логическая структура:** Оптимальная последовательность разделов
- **Подготовка к генерации:** Готовая схема для посекционной обработки

---

### Этап 8: Посекционная генерация статьи (Section-by-Section Generation) 🤖

**ВХОДНЫЕ ДАННЫЕ:**
- `ultimate_structure.json` из этапа 7
- Промпт `prompts/basic_articles/01_generate_section.txt`
- `topic` из командной строки для персонализации
- FREE DeepSeek Chat v3.1 API credentials (via OpenRouter)

**🎯 ЦЕЛЬ:** Сгенерировать статью по секциям с задержками против rate limits

**ФУНКЦИИ:**
- `src/llm_processing.py` → `generate_article_by_sections()` - главная функция
- Парсинг `structure[0]["article_structure"]` из ultimate structure
- FREE DeepSeek с fallback на Gemini 2.5 при таймаутах
- 5-секундные паузы между секциями для избежания rate limiting
- **Валидация v3.0:** 6-уровневая проверка качества (compression, entropy, bigrams, finish_reason)

**ПРОЦЕСС:**
1. **Парсинг структуры:** Извлечение секций из `ultimate_structure.json`
2. **Посекционная генерация:** Для каждой секции отдельно:
   - Отправка промпта с `{topic}`, `{section_title}`, `{section_structure}`
   - LLM генерирует HTML контент для конкретной секции
   - Сохранение в `sections/section_N/`
   - Пауза 5 секунд перед следующей секцией
3. **Сохранение секций:** Сырые секции сохраняются для этапа факт-чекинга

**ВЫХОДНЫЕ ДАННЫЕ:**
```json
{
  "raw_response": "JSON с объединенными секциями",
  "topic": "тема статьи",
  "generated_sections": [
    {
      "section_num": 0,
      "section_title": "Введение",
      "content": "HTML контент секции",
      "status": "success",
      "attempts": 1
    }
  ]
}
```

**Артефакты:**
- `08_article_generation/sections/section_1/` до `section_N/` - каждая секция отдельно
- `08_article_generation/wordpress_data.json` - метаданные статьи с сырыми секциями

---

### Этап 9: Посекционный перевод (Section-by-Section Translation) 🌍

**ВХОДНЫЕ ДАННЫЕ:**
- `generated_sections[]` из этапа 8 (генерация секций на русском)
- Переменная `--language` (целевой язык для перевода)
- `topic` из командной строки для контекста
- Промпт `prompts/basic_articles/09_translation.txt`
- FREE DeepSeek Chat v3.1 API credentials (via OpenRouter)

**🎯 ЦЕЛЬ:** Перевести каждую секцию отдельно с русского языка на целевой язык, сохранив HTML-разметку и структуру

**ФУНКЦИИ:**
- `src/llm_processing.py` → `translate_sections()` - главная функция посекционного перевода
- FREE DeepSeek с температурой 0.3 для естественного перевода
- Валидация каждой переведенной секции через `validate_content_quality()`
- Graceful fallback на Gemini 2.5 при ошибках

**ПРОЦЕСС:**
1. **Получение целевого языка:** Извлечение из `variables_manager.active_variables.get("language")` (default: "русский")
2. **Посекционный перевод:** Для каждой секции отдельно:
   - Подготовка промпта с контентом секции
   - LLM переводит HTML контент секции на целевой язык
   - Валидация качества переведенного контента (min 300 chars) через regex checks
   - Сохранение в `09_translation/section_N/`
   - Пауза 2 секунды перед следующей секцией
3. **Сохранение результатов:** Массив переведенных секций с метаданными

**ВЫХОДНЫЕ ДАННЫЕ:**
```json
{
  "sections": [
    {
      "section_num": 1,
      "section_title": "Introduction to DeepSeek",
      "content": "<h2>Introduction</h2><p>Translated content...</p>",
      "status": "translated",
      "original_content": "Оригинальный контент...",
      "translation_model": "deepseek-reasoner",
      "target_language": "english"
    }
  ]
}
```

**Артефакты:**
- `09_translation/section_1/` до `section_N/` - каждая переведенная секция отдельно
- `09_translation/translated_sections.json` - массив всех переведенных секций
- `09_translation/translation_status.json` - статус перевода (успех, failed_sections)

**КЛЮЧЕВЫЕ ОСОБЕННОСТИ:**
- ✅ **Посекционная обработка:** Каждая секция переводится независимо
- ✅ **Валидация v3.0:** 6-уровневая научная проверка через `LLMResponseValidator` (src/llm_validation.py) + `custom_validator=translation_validator`
- ✅ **Language verification:** Проверка соответствия целевому языку (>30% cyrillic для русского)
- ✅ **Length ratio check:** Перевод должен быть 80-125% от длины оригинала (через translation_validator)
- ✅ **Сохранение оригинала:** Original content сохраняется для отладки
- ⛔ **НЕ переводится:** HTML-теги, URL, код, команды терминала, технические термины
- 🔄 **Graceful fallback:** При ошибках переключение на Gemini 2.5

---

### Этап 10: Факт-чекинг секций (Fact-checking) 🔍

**ВХОДНЫЕ ДАННЫЕ:**
- `translated_sections[]` из этапа 9 (переведенные секции)
- Промпт `prompts/basic_articles/10_fact_check.txt`
- `topic` для контекстуализации
- Google Gemini 2.5 Flash API (с нативным веб-поиском)

**🎯 ЦЕЛЬ:** Проверить фактическую достоверность каждой секции через **нативный веб-поиск Google**

**ФУНКЦИИ:**
- `src/llm_processing.py` → `fact_check_sections()` - главная функция
- **Google Gemini с прямой интеграцией Google Search API**
- Группировка секций по 3 для эффективной обработки
- 3-секундные паузы между группами для rate limits

**ПРОЦЕСС:**
1. **Группировка:** Секции группируются по 3 для оптимизации
2. **Batch проверка:** Для каждой группы:
   - Отправка через Google Direct API с форматированием OpenAI→Google
   - **Автоматическое выполнение 10+ веб-поисков** через Google Search
   - Проверка версий, дат, статистики, технических деталей
   - Исправление фактических ошибок на основе актуальных данных
   - Добавление авторитетных ссылок (официальные docs, GitHub)
3. **Сохранение результатов:** Обновленные секции с пометкой fact_checked

**ВЫХОДНЫЕ ДАННЫЕ:**
```json
[
  {
    "section_num": 0,
    "section_title": "Введение",
    "content": "Проверенный HTML контент",
    "status": "fact_checked",
    "original_content": "Оригинальный контент для сравнения",
    "fact_check_model": "gemini-2.5-flash",
    "web_searches_performed": 12
  }
]
```

**Артефакты:**
- `10_fact_check/group_1/` до `group_N/` - проверенные группы секций
- `10_fact_check/fact_checked_content.json` - объединенный проверенный контент
- `10_fact_check/fact_check_status.json` - статус проверки

**КЛЮЧЕВЫЕ ОСОБЕННОСТИ:**
- **🔍 Нативный веб-поиск Google:** 10+ автоматических поисковых запросов
- **🌍 Работа на целевом языке:** Факт-чек выполняется на переведенном тексте
- **⚡ Batch обработка:** Группы по 3 секции для эффективности
- **✅ Высокое качество:** 9.5/10 vs 6/10 у Perplexity
- **🔗 Авторитетные ссылки:** Автоматическое добавление официальных источников
- **🛡️ Graceful fallback:** При ошибке fallback на DeepSeek без веб-поиска

---

### Этап 11: Расстановка ссылок (Link Placement) 🔗

**ВХОДНЫЕ ДАННЫЕ:**
- `translated_sections[]` из этапа 9 (переведенные секции)
- `fact_check_base_path` - путь к папке stage 10 (опционально)
- **Адаптивная логика данных:**
  - Если существуют `group_*` папки от fact-check → использовать их fact-checked контент
  - Если `group_*` не существуют (fact-check отключен) → создать новые группы из translated_sections
- Промпт `prompts/basic_articles/11_link_placement.txt`
- `topic` для контекстуализации
- Google Gemini 2.5 Flash API (с нативным веб-поиском)

**🎯 ЦЕЛЬ:** Автоматически добавить 10-20 авторитетных внешних ссылок естественным образом в текст статьи

**ФУНКЦИИ:**
- `src/llm_processing.py` → `place_links_in_sections()` - главная функция
- Группировка секций по 3 для оптимизации
- **Google Gemini 2.5 Flash с нативным веб-поиском** для поиска качественных источников
- Firecrawl Search API как дополнительный источник ссылок
- Fallback на stable Gemini 2.5 Flash при таймаутах
- 3-секундные паузы между группами для rate limits

**ПРОЦЕСС:**
0. **Проверка источника данных:**
   - Если `fact_check_base_path` существует и содержит `group_*` папки → загрузить fact-checked контент из `group_*/llm_responses_raw/*_fact_check_response.txt`
   - Иначе → создать новые группы по 3 секции из `translated_sections` (fallback поведение)
   - Логирование: "Found N fact-check groups" или "Creating new groups from translated_sections"
1. **Анализ контента**: LLM анализирует секции и определяет 10-20 позиций для размещения ссылок
2. **Генерация поисковых запросов**: Создаются запросы для поиска авторитетных источников
3. **Поиск кандидатов**: Firecrawl API ищет релевантные URL по запросам
4. **Фильтрация источников**:
   - Блокировка: reddit.com, medium.com, stackoverflow.com
   - Приоритизация: docs.* → arxiv.org → github.com → остальные
5. **Размещение маркеров**: Вставка [1], [2], [3] в HTML контент с умной коррекцией позиций
6. **Создание раздела ссылок**: Автоматическое добавление раздела "Полезные ссылки" в конец статьи

**ВЫХОДНЫЕ ДАННЫЕ:**
```json
{
  "content": "HTML контент с интегрированными ссылками и маркерами [1], [2], [3]",
  "links_placed": 18,
  "links_planned": 20,
  "success_rate": 90.0,
  "useful_links_section": "<h2>Полезные ссылки</h2><ol><li>...</li></ol>"
}
```

**Артефакты:**
- `11_link_placement/content_with_links.json` - контент с ссылками для редактуры
- `11_link_placement/link_placement_status.json` - статистика размещения
- `11_link_placement/group_1/`, `group_2/` - обработанные группы секций

**КЛЮЧЕВЫЕ ОСОБЕННОСТИ:**
- **🔍 Нативный веб-поиск Google**: Gemini находит качественные источники через Google Search API
- **🌍 Работа на целевом языке**: Ссылки добавляются на переведенный текст
- **🎯 Умное позиционирование**: Автоматическая коррекция позиций для предотвращения размещения внутри HTML тегов
- **📚 Академический приоритет**: Официальные документации и GitHub имеют приоритет
- **🛡️ Защита от ошибок**: Компактный JSON формат (только позиции) для стабильности
- **✅ Высокая успешность**: 90-95% запланированных ссылок успешно размещаются
- **🔄 Адаптация к режимам**: Автоматически использует группы от fact-check если они есть, иначе создает новые из translated_sections
- **⚙️ Опциональность**: Можно отключить через `--link-placement-mode off`
- **🔀 Поддержка всех сценариев**: Корректная работа при любой комбинации включенных/выключенных stage 10 и 11
- **🔄 Graceful fallback**: При ошибках автоматическое переключение на stable Gemini 2.5 Flash

---

### Этап 12: Редакторская обработка (Editorial Review) ✏️

**ВХОДНЫЕ ДАННЫЕ:**
- Контент с ссылками из этапа 11 (link placement)
- `topic` пользователя для тематической фокусировки
- Промпт `prompts/basic_articles/02_editorial_review.txt` (БЕЗ факт-чека)
- FREE DeepSeek Chat v3.1 API credentials (via OpenRouter)

**🎯 ЦЕЛЬ:** Техническая редактура и форматирование статьи (БЕЗ проверки фактов)

**ФУНКЦИИ:**
- `src/llm_processing.py` → `editorial_review()` - главная функция редакторской обработки с унифицированной retry системой
- FREE DeepSeek с низкой температурой (0.2) для стабильного редактирования
- 🆕 **Унифицированная retry/fallback система:** 6 попыток (3 primary + 3 fallback) через централизованный `make_llm_request()`
- 🆕 **Post-processor паттерн:** Автоматический retry/fallback при ошибках JSON парсинга после успешного LLM ответа
- 🆕 **5-уровневая JSON нормализация:** Universal repair → Direct parsing → Escaping fixes → Block extraction → Incomplete JSON repair
- 🆕 **Исправление переносов строк:** Автоматическое исправление `\\n` → реальные переносы для WordPress
- **Минимальная валидация:** `validation_level="minimal"` - только length ≥ 100 chars через `LLMResponseValidator` (контент уже проверен полной v3.0 валидацией на этапах 8-9)
- Полное логирование всех этапов retry и fallback процессов

**ПРОЦЕСС:**
1. **Загрузка промпта:** Специальный промпт для редактора (только форматирование)
2. **🆕 Унифицированная retry/fallback система:**
   - **Централизованная обработка:** Все retry/fallback логика в `make_llm_request()` (llm_request.py)
   - **6 автоматических попыток:** 3 primary (DeepSeek) + 3 fallback (Gemini 2.5)
   - **Post-processor интеграция:** Автоматический retry при ошибках JSON парсинга
   - **Сохранение всех попыток** для диагностики
3. **LLM редактура:** Выполняет:
   - Улучшение структуры контента (таблицы, списки, абзацы)
   - HTML форматирование и очистка markdown символов
   - Редакторский контроль текста (удаление "воды" и повторов)
   - Улучшение заголовков и метаданных
   - Оптимизация FAQ форматирования
   - Перевод англицизмов на русский (если язык русский)
4. **🆕 4-уровневая JSON нормализация:**
   - **Уровень 1:** Direct JSON parsing (стандартная очистка от ```json```)
   - **Уровень 2:** Fixing escaping issues (исправление экранирования)
   - **Уровень 3:** JSON block extraction (извлечение JSON блока через regex)
   - **Уровень 4:** Incomplete JSON repair (исправление незакрытых скобок)
5. **🆕 Исправление переносов строк:** Системное исправление `\\n` в реальные переносы строк для корректного отображения в WordPress
6. **Специальная обработка моделей:** Gemini-specific cleanup для корректного парсинга

**ВЫХОДНЫЕ ДАННЫЕ:**
```json
{
  "title": "Отредактированный заголовок",
  "content": "<h2>Улучшенный контент</h2><p>Отформатированный текст...</p>",
  "excerpt": "Привлекательное описание статьи",
  "slug": "optimized-url-slug",
  "_yoast_wpseo_title": "SEO-оптимизированный заголовок",
  "_yoast_wpseo_metadesc": "Интригующее мета-описание"
}
```

**Артефакты:**
- `12_editorial_review/wordpress_data_final.json` - финальная отредактированная статья с исправленными переносами строк
- `12_editorial_review/article_content_final.html` - чистый HTML контент
- `12_editorial_review/llm_requests/editorial_review_request.json`
- `12_editorial_review/llm_responses_raw/editorial_review_response.txt`

---

### WordPress Publication (Опциональный) 🌐

**ВХОДНЫЕ ДАННЫЕ:**
- Финальная отредактированная структура `wordpress_data_final.json` из этапа 12
- WordPress креденции из `.env` файла (PetrovA, app password)
- Флаг `--publish-wp` из командной строки
- WordPress API настройки

**🎯 ЦЕЛЬ:** Автоматически опубликовать статью на https://ailynx.ru в категории "prompts" в статусе черновика с полной поддержкой Yoast SEO

**ФУНКЦИИ:**
- `src/wordpress_publisher.py` → `WordPressPublisher()` - главный класс
- `publish_article()` - основная функция публикации
- `test_wordpress_connection()` - тестирование соединения
- WordPress REST API v2 интеграция
- Автоматическое управление категориями

**ПРОЦЕСС:**
1. **Тестирование соединения:** Проверка WordPress API и аутентификации
2. **Подготовка данных:** Адаптация JSON структуры для WordPress REST API
3. **Обработка категорий:** Поиск или создание категории "prompts" (ID: 825)
4. **Публикация статьи:** POST запрос к `/wp-json/wp/v2/posts` с полными данными
5. **SEO метаданные:** Автоматическая установка Yoast SEO полей через meta
6. **Сохранение результата:** Логирование WordPress ID и URL для редактирования

**ВЫХОДНЫЕ ДАННЫЕ:**
```json
{
  "success": true,
  "wordpress_id": 4377,
  "url": "https://ailynx.ru/wp-admin/post.php?post=4377&action=edit",
  "error": null
}
```

**Артефакты:**
- `wordpress_publication_result.json` - результат публикации с WordPress ID
- Логи процесса публикации в основном лог-файле

**КЛЮЧЕВЫЕ ОСОБЕННОСТИ:**
- **Опциональность:** Активируется только с флагом `--publish-wp`
- **Безопасность:** Статьи создаются в статусе `draft` для проверки
- **SEO интеграция:** Автоматическое заполнение всех Yoast SEO полей
- **Категоризация:** Все статьи автоматически попадают в категорию "prompts"
- **Валидация:** Полная проверка соединения и креденций перед публикацией
- **Обработка ошибок:** Детальное логирование и graceful fallback при сбоях
- **Аккаунт PetrovA:** Специальный аккаунт для Content Factory публикаций

---

## 🔧 **Техническая архитектура и управление (ОБНОВЛЕНО)**

### **Запуск пайплайна:**
```bash
# Полный 12-этапный пайплайн + WordPress (опционально)
python main.py "Лучшие промпты для создания идей для видео"

# С переводом на английский
python main.py "Промпты для анализа данных" --language "english"

# Полный пайплайн для guides с публикацией
python main.py "ChatGPT пошаговое руководство для начинающих" --content-type guides

# Создание категории WordPress (одноразово)
python create_prompts_category.py
```

### **Упрощенный поток данных (basic_articles):**
```
Этапы 1-6: Поиск, парсинг, оценка, отбор, очистка контента
           ↓
Этап 7: Извлечение структур из 5 источников → all_structures.json
           ↓
Этап 8: all_structures → ultimate_structure.json (создание единой структуры)
           ↓
Этап 08: ultimate_structure + topic → generated_sections[] (черновые секции на русском)
           ↓
Этап 09: generated_sections[] → translate_sections() → translated_sections[] (посекционный перевод)
           ↓
Этап 10: translated_sections[] → fact_check_sections() → group_* folders (факт-чек на целевом языке)
           ↓
Этап 11: translated_sections[] + fact_check_base_path → place_links_in_sections()
         (использует group_* если есть, иначе создает новые группы) → content_with_links
           ↓
Этап 12: content_with_links → editorial_review() → wordpress_data_final.json (отформатированная статья)
           ↓
WordPress: wordpress_data_final.json → WordPress API → draft post (опционально)
```

### **Обработка ошибок (ОБНОВЛЕНО - Oct 9, 2025):**
- **🆕 Унифицированная retry/fallback система (v2.4.0):**
  - **Централизованная логика:** Все retry/fallback в `make_llm_request()` (src/llm_request.py)
  - **6 автоматических попыток:** 3 primary + 3 fallback = максимальная надежность
  - **Post-processor паттерн:** Retry/fallback при ошибках JSON парсинга ПОСЛЕ успешного LLM ответа
  - **Применяется на ВСЕХ LLM этапах:** extract_sections, editorial_review, generate_article, fact_check, place_links, translate
- **🆕 Продвинутая валидация контента (v3.0):**
  - Провал валидации (спам, gibberish, < 300 chars) → exception → автоматический retry → fallback
  - Применяется селективно на этапах с критической валидацией (генерация, перевод, редактура)
- **🆕 5-уровневая JSON нормализация:** Universal repair → Direct parsing → Escaping fixes → Block extraction → Incomplete JSON repair
- **🆕 Model-specific обработка:** Специальная логика для Gemini vs DeepSeek
- **🆕 Исправление переносов строк:** Системное исправление `\\n` → реальные переносы для WordPress
- **Полное логирование запросов/ответов** для отладки с метками попыток
- **Graceful degradation** при сбоях LLM вызовов
- **Детальная диагностика:** Сохранение первых/последних 300 символов при ошибках парсинга

### **Post-Processor Coverage (v2.4.0):**

**Post-processor pattern** используется для downstream обработки (JSON parsing, normalization) с автоматическим retry/fallback при ошибках **ПОСЛЕ** успешного ответа от LLM API.

**Этапы С post-processors (3/7)**:
- **Этап 7 (extract_sections)**: `_extract_post_processor` - парсинг JSON array структур
- **Этап 8 (create_structure)**: `_create_structure_post_processor` - парсинг JSON object + нормализация формата
- **Этап 12 (editorial_review)**: `_editorial_post_processor` - парсинг JSON object с 5-уровневой нормализацией

**Этапы БЕЗ post-processors (4/7)** - возвращают HTML string напрямую:
- **Этап 08 (generate_article)**: Возвращает HTML контент секций, не требует JSON parsing
- **Этап 09 (translation)**: Возвращает переведенный HTML + custom validator для длины 80-125%
- **Этап 10 (fact_check)**: Возвращает исправленный HTML контент
- **Этап 11 (link_placement)**: Возвращает HTML с вставленными ссылками

**Ключевой принцип**: Post-processors нужны только там, где:
1. LLM возвращает JSON (не HTML)
2. Требуется downstream парсинг/нормализация ПОСЛЕ успешного ответа API
3. Есть риск ошибок парсинга, требующих retry/fallback

**Важно**: Все 7 LLM-зависимых этапов используют `make_llm_request()` для унифицированного retry/fallback, но только 3 из них требуют дополнительной JSON post-processing защиты.

### **Оптимизация производительности:**
- **Конкурентный скрапинг** (настройка через CONCURRENT_REQUESTS)
- **Умное кэширование** через сохранение артефактов
- **Токен оптимизация** (200 для примеров, 600 для комментариев)
- **Прогрессивное улучшение** (каждый этап развивает предыдущий)

### **Ключевые принципы дизайна (ОБНОВЛЕНО - Октябрь 2025):**
1. **Простота и эффективность**: Полный 13-этапный пайплайн с разделением обязанностей
2. **WordPress-ориентированность**: Прямая генерация и автоматическая публикация контента
3. **Качественное улучшение контента**: LLM дорабатывает найденный контент до идеального состояния
4. **🆕 ПОСЕКЦИОННАЯ ОБРАБОТКА**:
   - **Этап 08**: DeepSeek генерирует секции на русском
   - **Этап 09**: DeepSeek переводит КАЖДУЮ секцию отдельно на целевой язык
   - **Этап 10**: Google Gemini проверяет ФАКТЫ через нативный веб-поиск (на целевом языке)
   - **Этап 11**: Google Gemini находит и добавляет ССЫЛКИ через нативный веб-поиск (на целевом языке)
   - **Этап 12**: DeepSeek форматирует и полирует СТРУКТУРУ
5. **Прямая публикация**: Этап 13 сразу публикует готовый контент в WordPress
6. **Полная прозрачность**: Комплексное логирование всех LLM и WordPress взаимодействий
7. **Многоязычность**: Посекционный перевод на любой язык (по умолчанию русский)
8. **🆕 ОПТИМИЗИРОВАННАЯ СТОИМОСТЬ**:
   - Google Gemini ТОЛЬКО для факт-чека и link placement (где нужен нативный веб-поиск)
   - FREE DeepSeek для всех остальных этапов (структуры, генерация, перевод, редактура)
9. **🔗 ОБОГАЩЕНИЕ ССЫЛКАМИ**: Автоматическое добавление 10-20 авторитетных внешних ссылок
10. **SEO-оптимизация**: Автоматическое заполнение Yoast SEO полей для поисковых систем
11. **Безопасная публикация**: Статьи создаются в статусе draft для проверки перед публикацией
12. **Практическая ценность**: Фокус на реальных случаях использования и экспертных рекомендациях
13. **🆕 КАЧЕСТВО КОНТЕНТА**: Каждая секция проходит факт-проверку + обогащается ссылками + переводится

Эта полная 12-этапная архитектура (+ опциональная WordPress публикация) обеспечивает разделение ответственности: **Gemini проверяет факты + находит ссылки (веб-поиск)**, **DeepSeek генерирует + переводит + форматирует (FREE)**, что гарантирует высочайшее качество контента при оптимальной стоимости.

---

## 🔍 **Система сохранения сырых ответов LLM (ДОБАВЛЕНО: Сентябрь 2025)**

### **Назначение**
Автоматическое сохранение всех сырых ответов от LLM API для отладки проблем с JSON парсингом, особенно ошибок типа "Expecting value: line 5241 column 1 (char 28820)" от DeepSeek API.

### **Структура сохранения**
Каждый этап пайплайна сохраняет сырые ответы в свою папку:

```
output/{topic}/
├── 06_structure_extraction/
│   └── llm_responses_raw/
│       ├── extract_sections_response_attempt1_20250920_164532.txt
│       ├── extract_sections_response_attempt2_20250920_164545.txt
│       └── ERROR_extract_sections_response_attempt3_20250920_164558.txt
├── 07_ultimate_structure/
│   └── llm_responses_raw/
│       └── create_structure_response_attempt1_20250920_164612.txt
├── 08_article_generation/
│   └── sections/
│       ├── section_1/llm_responses_raw/
│       │   └── generate_article_response_attempt1_20250920_164625.txt
│       ├── section_2/llm_responses_raw/
│       └── ...
├── 09_editorial_review/
│   └── llm_responses_raw/
│       ├── ERROR_editorial_review_response_attempt1_20250920_164638.txt
│       └── editorial_review_response_attempt2_20250920_164651.txt
```

### **Именование файлов**

#### **Успешные ответы:**
```
{stage_name}_response_attempt{N}_{timestamp}.txt
```
- `stage_name`: extract_sections, create_structure, generate_article, editorial_review
- `attempt{N}`: номер попытки (1, 2, 3)
- `timestamp`: YYYYMMDD_HHMMSS

#### **Ошибочные ответы:**
```
ERROR_{stage_name}_response_attempt{N}_{timestamp}.txt
```
Сохраняются когда LLM API вернул ответ, но произошла ошибка парсинга JSON.

### **Формат содержимого файла**
```
TIMESTAMP: 2025-09-20T16:45:32.123456
MODEL: deepseek-reasoner
STAGE: editorial_review
ATTEMPT: 1
RESPONSE_LENGTH: 28820
SUCCESS: False
ERROR: Expecting value: line 5241 column 1 (char 28820)
================================================================================
{
  "title": "Улучшенный заголовок статьи",
  "content": "<h2>Введение</h2><p>Контент статьи...</p>
  // ЗДЕСЬ СЫРОЙ ОТВЕТ ОБРЫВАЕТСЯ ИЛИ СОДЕРЖИТ ПОВРЕЖДЕННЫЙ JSON
```

### **Применение для отладки**

#### **При ошибках JSON парсинга:**
1. Найти файл `ERROR_*` в папке проблемного этапа
2. Открыть файл и увидеть точное содержимое ответа LLM
3. Проанализировать где именно обрывается JSON или что вызывает ошибку
4. Понять причину: обрыв соединения, лимиты API, некорректный JSON от модели

#### **Пример типичных проблем:**
- **Обрыв соединения:** Ответ обрывается посередине JSON объекта
- **Превышение лимитов:** API возвращает HTML страницу с ошибкой вместо JSON
- **Некорректный JSON:** LLM генерирует невалидный JSON с неэкранированными кавычками
- **Кодировка:** Проблемы с UTF-8 символами в ответе

### **Технические детали**

#### **Автоматичность:**
- Система работает прозрачно, не требует дополнительной настройки
- Файлы создаются автоматически при каждом LLM запросе
- Не влияет на производительность (запись файлов в фоне)

#### **Место в коде:**
- Функция `_make_llm_request_with_retry_sync()` в `src/llm_processing.py`
- Сохранение происходит до парсинга JSON, сразу после получения ответа от API
- Поддерживается во всех LLM функциях: retry, timeout, sync, async

#### **Совместимость:**
- Работает со всеми этапами пайплайна
- Поддерживает все модели: DeepSeek, OpenRouter, Gemini
- Совместимо с существующей системой `save_llm_interaction()`

### **Преимущества**
1. **Полная прозрачность:** Видно точно что возвращает API
2. **Быстрая отладка:** Мгновенное понимание причины JSON ошибок
3. **Историчность:** Сохраняются все попытки для анализа паттернов
4. **Автономность:** Работает без дополнительных действий разработчика
5. **Структурированность:** Файлы организованы по этапам и времени

---

## TROUBLESHOOTING

### Частые проблемы и решения

#### 1. **Ошибка парсинга JSON от LLM**
**Симптомы:** `json.decoder.JSONDecodeError`
**Решение:**
- Проверьте `output/{topic}/*/llm_responses_raw/*.txt`
- Убедитесь что промпт требует JSON формат
- Проверьте fallback модели в config.py

#### 2. **Таймаут при парсинге сайтов**
**Симптомы:** Зависание на этапе 2 (Parse)
**Решение:**
- Увеличьте таймаут в src/config.py: `SECTION_TIMEOUT = 300`
- Проверьте блокировки на Firecrawl API

#### 3. **Недостаточно источников после фильтрации**
**Симптомы:** "После фильтрации осталось 0 источников"
**Решение:**
- Проверьте `filters/blocked_domains.json`
- Уменьшите `MIN_CONTENT_LENGTH` в config.py
- Расширьте поисковый запрос

#### 4. **Ошибка публикации в WordPress**
**Симптомы:** 401 Unauthorized или 403 Forbidden
**Решение:**
- Проверьте `WORDPRESS_APP_PASSWORD` в .env
- Убедитесь что Application Passwords включены
- Проверьте права пользователя

#### 5. **Превышен лимит токенов**
**Симптомы:** "Request too large" от API
**Решение:**
- Уменьшите `TOP_N_SOURCES` до 3-4
- Сократите промпты в `prompts/{type}/`
- Используйте более компактные модели

#### 6. **Дублирование контента в секциях**
**Симптомы:** Повторяющийся текст в разных секциях
**Решение:**
- Проверьте промпты генерации в `prompts/{type}/generate_article.md`
- Убедитесь что каждая секция имеет уникальный фокус

### Полезные команды для отладки

```bash
# Проверить последние ошибки
grep -r "ERROR" output/*/logs/

# Найти все неудачные LLM запросы
find output -name "*attempt[2-9]*" -type f

# Проверить размеры контента
find output -name "cleaned_content.txt" -exec wc -l {} \;

# Валидация JSON ответов
python -m json.tool output/{topic}/*/llm_responses_raw/*.txt

# Тест соединения с WordPress
curl -u "PetrovA:APP_PASSWORD" https://ailynx.ru/wp-json/wp/v2/posts
```

### Логи и диагностика

**Основные логи:**
- `output/{topic}/logs/pipeline.log` - общий лог пайплайна
- `output/{topic}/*/llm_responses_raw/` - сырые ответы LLM
- `batch_failed_topics.txt` - список неудачных тем (batch mode)

**Переменные окружения для отладки:**
```bash
export DEBUG_MODE=true        # Подробное логирование
export SKIP_WORDPRESS=true    # Пропустить публикацию
export USE_FALLBACK_ONLY=true # Использовать только fallback модели
```
